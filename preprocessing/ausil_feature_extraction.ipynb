{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8b350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import models\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db471a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AuSiL\n",
    "from feature_extraction.network_architectures import weak_mxh64_1024\n",
    "import feature_extraction.extractor as exm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9005a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watterfle dataset (FMA)\n",
    "from preprocessing import load_poly_encoder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa2e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_num = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b63aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/32000 [00:00<1:11:43,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Get MFCC with padding and crop======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [01:15<00:00, 425.29it/s] \n"
     ]
    }
   ],
   "source": [
    "last_pad_length = 938\n",
    "num_feature = 128\n",
    "cs, ns, labels, cs_path, ns_path = load_poly_encoder_dataset(last_pad_length, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f222dbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32000, 1, 938, 128]), torch.Size([32000, 1, 938, 128]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bsz * 10 개만 할당\n",
    "small_size = 32000\n",
    "cs = torch.tensor(cs[:small_size])\n",
    "ns = torch.tensor(ns[:small_size])\n",
    "labels = torch.tensor(labels[:small_size])\n",
    "\n",
    "cs = cs.view(-1, 1, last_pad_length, num_feature)\n",
    "ns = ns.view(-1, 1, last_pad_length, num_feature)\n",
    "\n",
    "cs.size(), ns.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d07bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feture extraction by pre-trained CNN\n",
    "trainType = 'weak_mxh64_1024'\n",
    "pre_model_path = 'feature_extraction/mx-h64-1024_0d3-1.17.pkl'\n",
    "featType = ['layer1', 'layer2', 'layer4', 'layer5', 'layer7', 'layer8', 'layer10', 'layer11', 'layer13', 'layer14', 'layer16', 'layer18'] # or layer 19 -  layer19 might not work well\n",
    "globalpoolfn = F.max_pool2d # can use max also\n",
    "netwrkgpl = F.avg_pool2d # keep it fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc50014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): featExtractor(\n",
       "    (layer1): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer4): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer7): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer8): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer10): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer11): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer13): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer14): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer16): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer18): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer19): Sequential(\n",
       "      (0): Conv2d(1024, 527, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "def load_model(netx,modpath):\n",
    "    state_dict = torch.load(modpath, map_location=lambda storage, loc: storage)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if 'module.' in k:\n",
    "            name = k[7:]\n",
    "        else:\n",
    "            name = k\n",
    "        new_state_dict[name] = v\n",
    "    netx.load_state_dict(new_state_dict)\n",
    "    \n",
    "netx = weak_mxh64_1024(527, netwrkgpl)\n",
    "load_model(netx, pre_model_path)\n",
    "\n",
    "feat_extractor = torch.nn.DataParallel(exm.featExtractor(netx, featType))\n",
    "\n",
    "feat_extractor.to(device_num)\n",
    "feat_extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded6c07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [25:56<00:00, 20.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# cs feature extraction\n",
    "cs_loader = DataLoader(cs, batch_size=1, num_workers=16, shuffle=False)\n",
    "\n",
    "pbar = tqdm(cs_loader)\n",
    "for i, spectrogram in enumerate(pbar):\n",
    "    p1d = (0, 0, 0, 1024-spectrogram.shape[2])\n",
    "    spectrogram = F.pad(spectrogram, p1d, \"constant\", 0)\n",
    "    features = []\n",
    "    #print('spectrogram', spectrogram.shape)\n",
    "    for j in range(spectrogram.shape[2]//128):\n",
    "        batch = spectrogram[:,:,j*128:(j+1)*128,:]\n",
    "        if batch.shape[0] > 0:\n",
    "            features.append(feat_extractor(batch.to(device_num)).data.cpu().numpy())\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    save_path = cs_path[i]\n",
    "    np.savez_compressed('{}_wlaf'.format(save_path), features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a73a4980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [25:57<00:00, 20.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#ns feature extraction\n",
    "ns_loader = DataLoader(ns, batch_size=1, num_workers=16, shuffle=False)\n",
    "\n",
    "pbar = tqdm(ns_loader)\n",
    "for i, spectrogram in enumerate(pbar):\n",
    "    p1d = (0, 0, 0, 1024-spectrogram.shape[2])\n",
    "    spectrogram = F.pad(spectrogram, p1d, \"constant\", 0)\n",
    "    features = []\n",
    "    #print('spectrogram', spectrogram.shape)\n",
    "    for j in range(spectrogram.shape[2]//128):\n",
    "        batch = spectrogram[:,:,j*128:(j+1)*128,:]\n",
    "        if batch.shape[0] > 0:\n",
    "            features.append(feat_extractor(batch.to(device_num)).data.cpu().numpy())\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    save_path = ns_path[i]\n",
    "    np.savez_compressed('{}_wlaf'.format(save_path), features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ns_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376decb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
