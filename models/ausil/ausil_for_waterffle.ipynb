{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8b350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9005a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted feature dateset from mel-spectrogram\n",
    "from preprocessing import load_ausil_feature_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa2e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_num = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a916bc3",
   "metadata": {},
   "source": [
    "# 1. load extracted features (by pre-trained CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5b63aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 79/32000 [00:00<00:40, 781.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Get extracted feature by pre-trained CNN ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:40<00:00, 786.75it/s]\n"
     ]
    }
   ],
   "source": [
    "cs, ns, labels = load_ausil_feature_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d919bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2972077  0.49398693 0.         ... 0.         0.0179748  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(cs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f222dbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([320, 8, 2528]), torch.Size([320, 8, 2528]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bsz * 10 개만 할당\n",
    "small_size = 320\n",
    "cs = torch.tensor(cs[:small_size])\n",
    "ns = torch.tensor(ns[:small_size])\n",
    "labels = torch.tensor(labels[:small_size])\n",
    "\n",
    "#cs = cs.view(-1, 1, last_pad_length, num_feature)\n",
    "#ns = ns.view(-1, 1, last_pad_length, num_feature)\n",
    "\n",
    "cs.size(), ns.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63cc3e2",
   "metadata": {},
   "source": [
    "# 2.PCA and attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d573a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PCA_layer(object):\n",
    "#     def __init__(self, dims=2528):\n",
    "#         with tf.variable_scope('PCA'):\n",
    "#             self.mean = tf.get_variable('mean_sift', dtype=tf.float32, trainable=False, shape=(dims,) )\n",
    "#             self.weights = tf.get_variable('weights', dtype=tf.float32, trainable=False, shape=(dims,dims))\n",
    "\n",
    "#     def __call__(self, logits):\n",
    "#         logits = logits - self.mean\n",
    "#         logits = tf.tensordot(logits, self.weights, axes=1)\n",
    "#         return logits\n",
    "\n",
    "class PCA_layer(nn.Module):\n",
    "    def __init__(self, dims=2528):\n",
    "        super(PCA_layer, self).__init__()        \n",
    "        self.mean = Variable(torch.randn(dims).type(torch.FloatTensor), requires_grad=False)\n",
    "        self.weights = Variable(torch.randn(dims, dims).type(torch.FloatTensor), requires_grad=False)\n",
    "        \n",
    "    def foward(self, logits):\n",
    "        logits = logits - self.mean\n",
    "        logits = tensordot(logits, self.weights, dims=2)\n",
    "        return logits\n",
    "    \n",
    "# class Attention_layer(object):\n",
    "\n",
    "#     def __init__(self, dims=2528):\n",
    "#         with tf.variable_scope('attention_layer'):\n",
    "#             self.context_vector = tf.get_variable('context_vector', dtype=tf.float32,\n",
    "#                                                   trainable=False, shape=(dims, 1))\n",
    "\n",
    "#     def __call__(self, logits):\n",
    "#         weights = tf.tensordot(logits, self.context_vector, axes=1) / 2.0 + 0.5\n",
    "#         return tf.multiply(logits, weights), weights\n",
    "\n",
    "class Attention_layer(nn.Module):\n",
    "    def __init__(self, dims=2528):\n",
    "        super(Attention_layer, self).__init__()\n",
    "        self.context_vector = Variable(torch.randn(dims, 1).type(torch.FloatTensor), requires_grad=False)\n",
    "        \n",
    "    def foward(self, logits):\n",
    "        weights = tensordot(logits, self.context_vector, dims=1) / 2.0 + 0.5\n",
    "        return multiply(logits, weights), weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53074b",
   "metadata": {},
   "source": [
    "# 3. AuSiL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639b3f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuSiL(object):\n",
    "    def __init__(self, model_dir):\n",
    "        super(AuSiL, self).__init__()\n",
    "        \n",
    "        # befor ausil PCA and attention\n",
    "        self.pca_layer = PCA_layer()\n",
    "        self.att_layer = Attention_layer()\n",
    "        \n",
    "        # ausil\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.fconv = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1)\n",
    "                    \n",
    "    def foward(self, cs, ns, labels):\n",
    "        # PCA & self-attention\n",
    "        cs_emb = self.extract_features(cs)\n",
    "        ns_emb = self.extract_features(ns)\n",
    "        \n",
    "        # Sim Matrix\n",
    "        sim = torch.matmul(self.cs_emb, torch.transpose(self.candidate))\n",
    "        \n",
    "        # AuSiL\n",
    "        sim = F.max_pool2d(F.relu(self.conv1(sim)), 2, stride=2)\n",
    "        #pad\n",
    "        sim = F.max_pool2d(F.relu(self.conv2(sim)), 2, stride=2)\n",
    "        sim = F.relu(self.conv3(sim))\n",
    "        sim = self.fconv(sim)\n",
    "        \n",
    "        sim = torch.clamp(a, min=-1, max=1)\n",
    "        \n",
    "        # similarity\n",
    "        sim = self.chamfer_similarity(sim)\n",
    "        \n",
    "    def extract_features(self, features):\n",
    "        # PCA\n",
    "        features = F.normalize(features,dim=-1,p=2)\n",
    "        features = self.pca_layer(features)\n",
    "        features = F.normalize(features,dim=-1,p=2)\n",
    "        # Attention\n",
    "        features, weights = self.att_layer(features)\n",
    "        return features\n",
    "    \n",
    "    def chamfer_similarity(self, sim, max_axis=1, mean_axis=0):\n",
    "        sim = torch.max(sim, max_axis, keepdim=True)\n",
    "        sim = torch.mean(sim, mean_axis, keepdim=True)\n",
    "        # tf.squeeze(sim, [max_axis, mean_axis])\n",
    "        sim = torch.squeeze(sim, 0)\n",
    "        sim = torch.squeeze(sim, 0)\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75029476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
