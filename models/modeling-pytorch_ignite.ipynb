{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7afcbe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f5d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('/home/super/waterffle/playlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "223052c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c337a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preprocessing import load_poly_encoder_dataset\n",
    "# now_mfcc_list, next_mfcc_list, label_list = load_poly_encoder_dataset(2800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5478df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsz * 10 개만 할당\n",
    "# now_mfcc_list = torch.tensor(now_mfcc_list[:320])\n",
    "# next_mfcc_list = torch.tensor(next_mfcc_list[:320])\n",
    "# label_list = torch.tensor(label_list[:320])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d31fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 메모리 일부로 제한\n",
    "# torch.cuda.set_per_process_memory_fraction(0.5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2384a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3efbf1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import load_poly_encoder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b30c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30540cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_pad_length = 2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "639b0d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Get MFCC with padding and crop======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 32000/32000 [00:23<00:00, 1383.91it/s]\n"
     ]
    }
   ],
   "source": [
    "cs, ns, labels = load_poly_encoder_dataset(last_pad_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca15b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsz * 10 개만 할당\n",
    "part = 320\n",
    "cs = torch.tensor(cs[:part])\n",
    "ns = torch.tensor(ns[:part])\n",
    "labels = torch.tensor(labels[:part])\n",
    "\n",
    "# cs = torch.tensor(cs)\n",
    "# ns = torch.tensor(ns)\n",
    "# labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42372c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = cs.view(-1, 1, last_pad_length, 40)\n",
    "ns = ns.view(-1, 1, last_pad_length, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebdc9967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([320, 1, 2800, 40]), torch.Size([320, 1, 2800, 40]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.size(), ns.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620b5bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2800, 40])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4fccc",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f1a59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afe01878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from collections.abc import Iterable\n",
    "from itertools import repeat\n",
    "\n",
    "\"\"\"Near infinity, useful as a large penalty for scoring when inf is bad.\"\"\"\n",
    "NEAR_INF = 1e20\n",
    "NEAR_INF_FP16 = 65504\n",
    "\n",
    "def _pair(v):\n",
    "    if isinstance(v, Iterable):\n",
    "        assert len(v) == 2, \"len(v) != 2\"\n",
    "        return v\n",
    "    return tuple(repeat(v, 2))\n",
    "\n",
    "\n",
    "def infer_conv_output_dim(conv_op, input_dim, sample_inchannel):\n",
    "    sample_seq_len = 200\n",
    "    sample_bsz = 10\n",
    "    x = torch.randn(sample_bsz, sample_inchannel, sample_seq_len, input_dim)\n",
    "    # N x C x H x W\n",
    "    # N: sample_bsz, C: sample_inchannel, H: sample_seq_len, W: input_dim\n",
    "    x = conv_op(x)\n",
    "    # N x C x H x W\n",
    "    x = x.transpose(1, 2)\n",
    "    # N x H x C x W\n",
    "    bsz, seq = x.size()[:2]\n",
    "    per_channel_dim = x.size()[3]\n",
    "    # bsz: N, seq: H, CxW the rest\n",
    "    return x.contiguous().view(bsz, seq, -1).size(-1), per_channel_dim\n",
    "\n",
    "\n",
    "'''\n",
    "Two 2-D convolutional blocks, each with two conv. layers with kernel size=3, max-pooling kernel=2. The first block has 64 feature maps while the second has 128\n",
    "'''\n",
    "class ConvEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    VGG motibated cnn module https://arxiv.org/pdf/1409.1556.pdf\n",
    "    code : https://github.com/pytorch/fairseq/blob/c36294ea4fd35eac757f417de9668b32c57d4b3d/fairseq/modules/vggblock.py#L38\n",
    "    Args:\n",
    "        in_channels: (int) number of input channels (typically 1)\n",
    "        out_channels: (int) number of output channels\n",
    "        conv_kernel_size: convolution channels\n",
    "        pooling_kernel_size: the size of the pooling window to take a max over\n",
    "        num_conv_layers: (int) number of convolution layers\n",
    "        input_dim: (int) input dimension\n",
    "        conv_stride: the stride of the convolving kernel.\n",
    "            Can be a single number or a tuple (sH, sW)  Default: 1\n",
    "        padding: implicit paddings on both sides of the input.\n",
    "            Can be a single number or a tuple (padH, padW). Default: None\n",
    "        layer_norm: (bool) if layer norm is going to be applied. Default: False\n",
    "    Shape:\n",
    "        Input: BxCxTxfeat, i.e. (batch_size, input_size, timesteps, features)\n",
    "        Output: BxCxTxfeat, i.e. (batch_size, input_size, timesteps, features)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels,\n",
    "                 conv_kernel_size,\n",
    "                 num_conv_layers,\n",
    "                 pooling_kernel_size,\n",
    "                 input_dim=None, \n",
    "                 conv_stride=1,\n",
    "                 padding=None,\n",
    "                 layer_norm=True\n",
    "                 ):\n",
    "        assert (\n",
    "            input_dim is not None\n",
    "        ), \"Need input_dim for LayerNorm and infer_conv_output_dim\"\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        \n",
    "        conv_kernel_size = _pair(conv_kernel_size)\n",
    "        pooling_kernel_size = _pair(pooling_kernel_size)\n",
    "        padding = (\n",
    "            tuple(e // 2 for e in conv_kernel_size)\n",
    "            if padding is None\n",
    "            else _pair(padding)\n",
    "        )\n",
    "        conv_stride = _pair(conv_stride)\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # input_channels=1 : mfcc는 2d이므로 채널을 1로 봐야함.\n",
    "        # kernel size 3\n",
    "        for layer in range(num_conv_layers):\n",
    "            conv_op = nn.Conv2d(\n",
    "                in_channels if layer == 0 else out_channels,\n",
    "                out_channels,\n",
    "                conv_kernel_size,\n",
    "                stride=conv_stride,\n",
    "                padding=padding,\n",
    "            )\n",
    "            self.layers.append(conv_op)\n",
    "            if layer_norm:\n",
    "                self.conv_output_dim, per_channel_dim = infer_conv_output_dim(\n",
    "                    conv_op, input_dim, in_channels if layer == 0 else out_channels\n",
    "                )\n",
    "                self.layers.append(nn.LayerNorm(per_channel_dim))\n",
    "                input_dim = per_channel_dim\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        if pooling_kernel_size is not None:\n",
    "            # ceil_mode : when True, will use ceil instead of floor to compute the output shape\n",
    "            pool_op = nn.MaxPool2d(kernel_size=pooling_kernel_size, ceil_mode=True)\n",
    "            self.layers.append(pool_op)\n",
    "            self.total_output_dim, self.output_dim = infer_conv_output_dim(\n",
    "                pool_op, input_dim, out_channels\n",
    "            )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        for i, _ in enumerate(self.layers):\n",
    "            x = self.layers[i](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements simple/classical attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int = 1,\n",
    "        attn: str = 'cosine',\n",
    "        residual: bool = False,\n",
    "        get_weights: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if attn == 'cosine':\n",
    "            self.cosine = nn.CosineSimilarity(dim=dim)\n",
    "        self.attn = attn\n",
    "        self.dim = dim\n",
    "        self.get_weights = get_weights\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        xs: torch.Tensor,\n",
    "        ys: torch.Tensor,\n",
    "        mask_ys: Optional[torch.Tensor] = None,\n",
    "        values: Optional[torch.Tensor] = None,\n",
    "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Compute attention.\n",
    "        Attend over ys with query xs to obtain weights, then apply weights to\n",
    "        values (ys if yalues is None)\n",
    "        Args:\n",
    "            xs: B x query_len x dim (queries)\n",
    "            ys: B x key_len x dim (keys)\n",
    "            mask_ys: B x key_len (mask)\n",
    "            values: B x value_len x dim (values); if None, default to ys\n",
    "        \"\"\"\n",
    "        bsz = xs.size(0)\n",
    "        y_len = ys.size(1)\n",
    "        x_len = xs.size(1)\n",
    "        if self.attn == 'cosine':\n",
    "            l1 = self.cosine(xs, ys).unsqueeze(self.dim - 1)\n",
    "        else:\n",
    "            l1 = torch.bmm(xs, ys.transpose(1, 2))\n",
    "            if self.attn == 'sqrt':\n",
    "                d_k = ys.size(-1)\n",
    "                l1 = l1 / math.sqrt(d_k)\n",
    "        if mask_ys is not None:\n",
    "            attn_mask = (mask_ys == 0).view(bsz, 1, y_len)\n",
    "            attn_mask = attn_mask.repeat(1, x_len, 1)\n",
    "            l1.masked_fill_(attn_mask, neginf(l1.dtype))\n",
    "        l2 = F.softmax(l1, dim=self.dim, dtype=torch.float).type_as(l1)\n",
    "        if values is None:\n",
    "            values = ys\n",
    "        lhs_emb = torch.bmm(l2, values)\n",
    "\n",
    "        # # add back the query\n",
    "        if self.residual:\n",
    "            lhs_emb = lhs_emb.add(xs)\n",
    "        \n",
    "        res = lhs_emb.squeeze(self.dim - 1)\n",
    "        if self.get_weights:\n",
    "            return res, l2\n",
    "        else:\n",
    "            return res\n",
    "        \n",
    "\n",
    "class PolyBasicAttention(BasicAttention):\n",
    "    \"\"\"\n",
    "    Override basic attention to account for edge case for polyencoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, poly_type, n_codes, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.poly_type = poly_type\n",
    "        self.n_codes = n_codes\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        Account for accidental dimensionality reduction when num_codes is 1 and the\n",
    "        polyencoder type is 'codes'\n",
    "        \"\"\"\n",
    "        lhs_emb = super().forward(*args, **kwargs)\n",
    "        if self.poly_type == 'codes' and self.n_codes == 1 and len(lhs_emb.shape) == 2:\n",
    "            lhs_emb = lhs_emb.unsqueeze(self.dim - 1)\n",
    "        return lhs_emb\n",
    "    \n",
    "\n",
    "def neginf(dtype: torch.dtype) -> float:\n",
    "    \"\"\"\n",
    "    Return a representable finite number near -inf for a dtype.\n",
    "    \"\"\"\n",
    "    if dtype is torch.float16:\n",
    "        return -NEAR_INF_FP16\n",
    "    else:\n",
    "        return -NEAR_INF\n",
    "    \n",
    "\n",
    "class AudioEncoder(nn.Module):\n",
    "    '''\n",
    "    code : https://github.com/pytorch/fairseq/blob/c36294ea4fd35eac757f417de9668b32c57d4b3d/examples/speech_recognition/models/vggtransformer.py#L271\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 poly_n_codes, # m, the number of global contxt features\n",
    "                 poly_attention_num_heads,\n",
    "                 num_att_layers,\n",
    "                 codes_attention_num_heads,\n",
    "                 embed_dim, \n",
    "                \n",
    "                 input_feat_per_channel,\n",
    "                 num_conv_block,\n",
    "                 num_conv_layers, \n",
    "                 in_channels, \n",
    "                 out_channels,\n",
    "                 conv_kernel_size=3, \n",
    "                 pooling_kernel_size=2,\n",
    "                 layer_norm=False,\n",
    "                 dropout=0.1,\n",
    "                 reduction_type='first' # first, avg, max\n",
    "                ):\n",
    "        super(AudioEncoder, self).__init__()\n",
    "                \n",
    "        self.in_channels = in_channels\n",
    "        self.input_dim = input_feat_per_channel\n",
    "        self.reduction_type = reduction_type\n",
    "        \n",
    "        self.conv_encoder_block = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_conv_block):\n",
    "            self.conv_encoder_block.append(\n",
    "                ConvEncoder(\n",
    "                    in_channels=in_channels, \n",
    "                    out_channels=out_channels,\n",
    "                    conv_kernel_size=conv_kernel_size,\n",
    "                    num_conv_layers=num_conv_layers,\n",
    "                    pooling_kernel_size=pooling_kernel_size,\n",
    "                    input_dim=input_feat_per_channel,\n",
    "                    layer_norm=layer_norm\n",
    "                    )\n",
    "                )\n",
    "            in_channels = out_channels\n",
    "            input_feat_per_channel = self.conv_encoder_block[-1].output_dim\n",
    "        \n",
    "        self.conv_encoder_block = nn.Sequential(*self.conv_encoder_block)\n",
    "        \n",
    "        # conv_output_dim is the output dimension of conv encoder\n",
    "        conv_output_dim = self.infer_conv_output_dim(self.in_channels, self.input_dim)\n",
    "        \n",
    "        self.n_codes = poly_n_codes\n",
    "        self.attention_num_heads = poly_attention_num_heads\n",
    "        self.codes_attention_num_heads = codes_attention_num_heads\n",
    "\n",
    "        # the codes\n",
    "        codes = torch.empty(self.n_codes, embed_dim)\n",
    "        codes = torch.nn.init.uniform_(codes)\n",
    "        self.codes = torch.nn.Parameter(codes)\n",
    "\n",
    "        # attention for the codes\n",
    "        self.code_attention = PolyBasicAttention(poly_type='codes', n_codes=self.n_codes, dim=2, attn='basic', get_weights=False)\n",
    "\n",
    "        # The final attention (the one that takes the candidate as key)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, \n",
    "                                               num_heads=self.attention_num_heads, \n",
    "                                               dropout=0.0)\n",
    "#         self.attention = PolyBasicAttention(poly_type='codes', n_codes=self.n_codes, dim=2, attn='basic', get_weights=False)\n",
    "\n",
    "        \n",
    "        self.att_encoder_block = nn.ModuleList()\n",
    "        \n",
    "        # conv encoder를 거쳐나온 데이터의 dim과 embed_dim이 다를 경우 맞춰준다\n",
    "        if conv_output_dim != embed_dim:\n",
    "            self.att_encoder_block.append(nn.Linear(conv_output_dim, embed_dim))\n",
    "        \n",
    "        # SelfAttentionEncoder * num_att_layers\n",
    "        for i in range(num_att_layers):\n",
    "            self.att_encoder_block.append(\n",
    "                torch.nn.TransformerEncoderLayer(d_model=embed_dim, \n",
    "                                                 nhead=self.attention_num_heads, \n",
    "                                                 dim_feedforward=embed_dim*4, \n",
    "                                                 dropout=dropout, \n",
    "                                                 activation='gelu')\n",
    "            )\n",
    "                            \n",
    "        self.att_encoder_block = nn.Sequential(*self.att_encoder_block)\n",
    "\n",
    "            \n",
    "    def attend(self, attention_layer, queries, keys, values, mask):\n",
    "        \"\"\"\n",
    "        Apply attention.\n",
    "        :param attention_layer:\n",
    "            nn.Module attention layer to use for the attention\n",
    "        :param queries:\n",
    "            the queries for attention\n",
    "        :param keys:\n",
    "            the keys for attention\n",
    "        :param values:\n",
    "            the values for attention\n",
    "        :param mask:\n",
    "            mask for the attention keys\n",
    "        :return:\n",
    "            the result of applying attention to the values, with weights computed\n",
    "            wrt to the queries and keys.\n",
    "        \"\"\"\n",
    "        if keys is None:\n",
    "            keys = values\n",
    "        if isinstance(attention_layer, PolyBasicAttention):\n",
    "            return attention_layer(queries, keys, values=values, mask_ys=mask)\n",
    "        elif isinstance(attention_layer, nn.MultiheadAttention):\n",
    "            return attention_layer(query=queries, key=keys, value=values, attn_mask=mask)[0]\n",
    "\n",
    "        else:\n",
    "            raise Exception('Unrecognized type of attention')\n",
    "\n",
    "    def encode(self, xs):\n",
    "        # x_raw = [current song, next song]\n",
    "        # next: candidate\n",
    "        cs, ns = xs\n",
    "        \n",
    "        # padded tensor\n",
    "        # B, C, T, F\n",
    "        bsz, in_channels, max_seq_len, _ = ns.size()\n",
    "\n",
    "        # cand mfcc를 conv encoder를 거친 emb\n",
    "        cand_emb = self.conv_encoder_block(ns)\n",
    "\n",
    "        bsz, _, output_seq_len, _ = cand_emb.size()\n",
    "\n",
    "        # (B, C, T, F) -> (B, T, C, F) -> (B, T, C*F)\n",
    "        cand_emb = cand_emb.transpose(1, 2)\n",
    "        cand_emb = cand_emb.contiguous().view(bsz, output_seq_len, -1)\n",
    "\n",
    "        # transformer encoder\n",
    "        cand_emb = self.att_encoder_block(cand_emb)\n",
    "\n",
    "        # reduction : first, avg, max\n",
    "        if self.reduction_type=='first':\n",
    "            cand_emb = cand_emb[:,0,:]\n",
    "        elif self.reduction_type == 'avg':\n",
    "            cand_emb = torch.mean(cand_emb, dim=1)\n",
    "        elif self.reduction_type == 'max':\n",
    "            cand_emb = torch.max(cand_emb, dim=1).values\n",
    "        else:\n",
    "            raise KeyError('Not Registered reduction_type. Capable options : first, avg, and max')\n",
    "        cand_emb = cand_emb.view(cand_emb.size()[0], 1, cand_emb.size()[1])\n",
    "\n",
    "        # ctxt mfcc를 conv encoder를 거친 emb\n",
    "        ctxt_out = self.conv_encoder_block(cs)\n",
    "        b, c, t, f = ctxt_out.size()\n",
    "\n",
    "        # (B, C, T, F) -> (B, T, C, F) -> (B, T, C*F)\n",
    "        ctxt_out = ctxt_out.transpose(1, 2)\n",
    "        ctxt_out = ctxt_out.contiguous().view(b, t, -1)\n",
    "\n",
    "        # transformer encoder\n",
    "        ctxt_out = self.att_encoder_block(ctxt_out)\n",
    "\n",
    "        return ctxt_out, cand_emb\n",
    "                \n",
    "    def forward(self, x_raw=None, x_rep=None):\n",
    "        \n",
    "        if x_raw is not None:\n",
    "            return self.encode(x_raw)\n",
    "        elif x_rep is not None:\n",
    "            ctxt_out, cand_emb = x_rep\n",
    "\n",
    "            # m개 만큼 context code를 반복\n",
    "            # ctxt_out 값과 code를 내적한 값들의 softmax한 벡터 (w_1,...,w_m)를 이전 레이어 결과값(ctxt_out)과 곱해서 합한다.\n",
    "            # 이 값이 m개의 global context features\n",
    "            bsz = cand_emb.size(0)\n",
    "    #             print(f'cand_emb after encoding : {cand_emb.size()}')\n",
    "    #             print(f'cand_emb : {cand_emb}\\n')\n",
    "    #             print(f'ctxt_out after encoding : {ctxt_out.size()}')\n",
    "            global_ctxts = self.attend(attention_layer=self.code_attention , \n",
    "                                       queries=self.codes.repeat(bsz, 1, 1), \n",
    "                                       keys=ctxt_out,\n",
    "                                       values=ctxt_out, \n",
    "                                       mask=None) \n",
    "    #             print(f'global_ctxts : {global_ctxts.size()}')\n",
    "\n",
    "            # torch.nn.MultiheadAttention은 (seq_len, bsz, embed_dim) 으로 입력값을 받아서 수정\n",
    "            global_ctxts = global_ctxts.transpose(0,1)\n",
    "\n",
    "    #             print(f'global_ctxts : {global_ctxts.size()}')\n",
    "    #             print(f'cand_emb : {cand_emb}\\n')\n",
    "            cand_emb = cand_emb.transpose(0,1)\n",
    "\n",
    "            # m개의 global context features를 cand_emb와 내적한 값을 softmax한 벡터를 (w_1,...,w_m)라 할 때, 이 가중치 값과 global contxt features를 곱해서 합한다.\n",
    "            # 이 값이 최종 ctxt_emb\n",
    "            ctxt_emb = self.attend(attention_layer=self.attention ,\n",
    "                                   queries=cand_emb, \n",
    "                                   keys=global_ctxts,\n",
    "                                   values=global_ctxts,\n",
    "                                   mask=None)\n",
    "    #             ctxt_emb = ctxt_emb.transpose(0, 1)\n",
    "    #             print(f'ctxt_emb size : {ctxt_emb.size()}')\n",
    "\n",
    "    #             print(f'ctxt_emb : {ctxt_emb}\\n')\n",
    "\n",
    "            # score: cand_emb와 ctxt_emb 간 cosine similarity값 (반환값)\n",
    "            scores = torch.sum(ctxt_emb * cand_emb, -1)\n",
    "            scores = scores.view(1, -1)\n",
    "    #             print(f'scores : {scores.size()}')\n",
    "    #             print(f'scores : {scores}')\n",
    "            return scores\n",
    "        else:\n",
    "            raise Exception('not support Operation')\n",
    "    \n",
    "    def infer_conv_output_dim(self, in_channels, input_dim):\n",
    "        sample_seq_len = 200\n",
    "        sample_bsz = 10\n",
    "        x = torch.randn(sample_bsz, in_channels, sample_seq_len, input_dim)\n",
    "        for i, _ in enumerate(self.conv_encoder_block):\n",
    "            x = self.conv_encoder_block[i](x)\n",
    "        # (B, C, T, F) -> (B, T, C, F) -> (B, T, C*F)\n",
    "        x = x.transpose(1, 2)\n",
    "        mb, seq = x.size()[:2]\n",
    "        return x.contiguous().view(mb, seq, -1).size(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74b2c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioEncoder(\n",
    "                     poly_n_codes=64, # m, the number of global contxt features\n",
    "                     poly_attention_num_heads=8, \n",
    "                     codes_attention_num_heads=2,\n",
    "                     num_att_layers=6,\n",
    "                     embed_dim=512, \n",
    "                     input_feat_per_channel=40, # feature vector dimension\n",
    "                     num_conv_block=2,\n",
    "                     num_conv_layers=2, \n",
    "                     in_channels=1, \n",
    "                     out_channels=32,\n",
    "                     conv_kernel_size=3, \n",
    "                     pooling_kernel_size=2,\n",
    "                     layer_norm=True,\n",
    "                     reduction_type='first'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072292ab",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5905c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events #, create_supervised_trainer, create_supervised_evaluator\n",
    "# from ignite.metrics import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89729824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(data, bsz, shuffle=True):\n",
    "    #TODO encoding 후 np array 혹은 cpu에 할당하고 나서 gpu 사용량을 줄이는 시도\n",
    "    cs_rep, ns_rep, labels = data\n",
    "    length = cs_rep.size()[0]\n",
    "\n",
    "    for i in range(0, length, bsz):\n",
    "        cs_batch = cs_rep[i:i+bsz]\n",
    "        ns_batch = ns_rep[i:i+bsz]\n",
    "        label_batch = labels[i:i+bsz]\n",
    "\n",
    "        if shuffle:\n",
    "            indexes = torch.randperm(bsz)              \n",
    "            yield [[cs_batch[indexes], ns_batch[indexes]], label_batch[indexes]]\n",
    "        else:\n",
    "            yield [[cs_batch, ns_batch], label_batch]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "939deeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(raw_data, train_batch_size, val_batch_size=None, val_ratio=0.2):\n",
    "    if val_ratio > 0:\n",
    "        train_len = int((1-val_ratio)*len(labels))\n",
    "        trainset = [cs[:train_len], ns[:train_len], labels[:train_len]]\n",
    "        valset = [cs[train_len:], ns[train_len:], labels[train_len:]]\n",
    "    else:\n",
    "        trainset = raw_data\n",
    "        valset = None\n",
    "    t_total = len(trainset[2])\n",
    "    \n",
    "    train_loader = train_batch(trainset, train_batch_size, shuffle=True)\n",
    "    if valset is not None:\n",
    "        if val_batch_size is None:\n",
    "            val_batch_size = train_batch_size\n",
    "        val_loader = train_batch(valset, val_batch_size, shuffle=False)\n",
    "        return t_total, train_loader, val_loader\n",
    "    return t_total, train_loader, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0937086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Sequence, Tuple, Union\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n",
    "\n",
    "\n",
    "class RetrievalAccuracy(Metric):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_transform: Callable = lambda x:x,\n",
    "        device: Union[str, torch.device] = torch.device('cpu'),\n",
    "    ):\n",
    "        super(RetrievalAccuracy, self).__init__(output_transform=output_transform, device=device)\n",
    "#         self._device=device\n",
    "    \n",
    "    @reinit__is_reduced\n",
    "    def reset(self) -> None:\n",
    "        self._num_correct = torch.tensor(0, device=self._device)\n",
    "        self._len = 0\n",
    "        super(RetrievalAccuracy, self).reset()\n",
    "    \n",
    "    @reinit__is_reduced\n",
    "    def update(self, output: Sequence[torch.Tensor]) -> None:\n",
    "        logit, y = output[0].detach(), output[1].detach()\n",
    "        \n",
    "        y_pred = torch.argmax(logit, axis=1).item()\n",
    "        y = torch.argmax(y).item()\n",
    "        \n",
    "        print(f'y_pred {y_pred}, y {y}')\n",
    "        \n",
    "        if y_pred == y:\n",
    "            self._num_correct += torch.tensor(1).to(self._device)\n",
    "            \n",
    "        self._len += 1\n",
    "        print(f'_len : {self._len}')\n",
    "    \n",
    "    @sync_all_reduce(\"_len\", \"_num_correct\")\n",
    "    def compute(self) -> float:\n",
    "        if self._len == 0:\n",
    "            return 0.0\n",
    "#             raise NotComputableError('Accuracy must have at least one example before it can be computed.')\n",
    "        return self._num_correct.item() / self._len\n",
    "    \n",
    "    \n",
    "# class Loss(Metric):\n",
    "#     def __init__(self):\n",
    "#         super(RetrievalAccuracy, self).__init__()\n",
    "#         self.reset()\n",
    "        \n",
    "#     def reset(self):\n",
    "#         self._cost = 0\n",
    "#         self._len = 0\n",
    "        \n",
    "#     def update(self, output):\n",
    "#         logit, y = output\n",
    "                \n",
    "#         # label\n",
    "#         y = torch.LongTensor([torch.argmax(y).item()]).to(device)\n",
    "            \n",
    "#         loss = criterion(logit, y)\n",
    "        \n",
    "#         if y_pred == y:\n",
    "#             self._num_correct += 1\n",
    "            \n",
    "#         self._len += 1\n",
    "    \n",
    "#     def compute(self):\n",
    "#         if self._len == 0:\n",
    "#             raise ValueError('length : 0')\n",
    "#         return self._num_correct / self._len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df8a9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Sequence, Tuple, Union, cast\n",
    "\n",
    "import torch\n",
    "\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n",
    "\n",
    "__all__ = [\"Loss\"]\n",
    "\n",
    "\n",
    "class Loss(Metric):\n",
    "    \"\"\"\n",
    "    ref : https://github.com/pytorch/ignite/blob/786aea82725ef114737913f76599665bc15b5de5/ignite/metrics/loss.py\n",
    "    \n",
    "    Calculates the average loss according to the passed loss_fn.\n",
    "    Args:\n",
    "        loss_fn: a callable taking a prediction tensor, a target\n",
    "            tensor, optionally other arguments, and returns the average loss\n",
    "            over all observations in the batch.\n",
    "        output_transform: a callable that is used to transform the\n",
    "            :class:`~ignite.engine.engine.Engine`'s ``process_function``'s output into the\n",
    "            form expected by the metric.\n",
    "            This can be useful if, for example, you have a multi-output model and\n",
    "            you want to compute the metric with respect to one of the outputs.\n",
    "            The output is expected to be a tuple `(prediction, target)` or\n",
    "            (prediction, target, kwargs) where kwargs is a dictionary of extra\n",
    "            keywords arguments. If extra keywords arguments are provided they are passed to `loss_fn`.\n",
    "        batch_size: a callable taking a target tensor that returns the\n",
    "            first dimension size (usually the batch size).\n",
    "        device: specifies which device updates are accumulated on. Setting the\n",
    "            metric's device to be the same as your ``update`` arguments ensures the ``update`` method is\n",
    "            non-blocking. By default, CPU.\n",
    "    Attributes:\n",
    "        required_output_keys: dictionary defines required keys to be found in ``engine.state.output`` if the\n",
    "            latter is a dictionary. Default, ``(\"y_pred\", \"y\", \"criterion_kwargs\")``. This is useful when the\n",
    "            criterion function requires additional arguments, which can be passed using ``criterion_kwargs``.\n",
    "            See notes below for an example.\n",
    "    Note:\n",
    "        Let's implement a Loss metric that requires ``x``, ``y_pred``, ``y`` and ``criterion_kwargs`` as input\n",
    "        for ``criterion`` function. In the example below we show how to setup standard metric like Accuracy\n",
    "        and the Loss metric using an ``evaluator`` created with\n",
    "        :meth:`~ignite.engine.create_supervised_evaluator` method.\n",
    "        .. code-block:: python\n",
    "            import torch\n",
    "            import torch.nn as nn\n",
    "            from torch.nn.functional import nll_loss\n",
    "            from ignite.metrics import Accuracy, Loss\n",
    "            from ignite.engine import create_supervised_evaluator\n",
    "            model = ...\n",
    "            criterion = nll_loss\n",
    "            metrics = {\n",
    "                \"Accuracy\": Accuracy(),\n",
    "                \"Loss\": Loss(criterion)\n",
    "            }\n",
    "            # global criterion kwargs\n",
    "            criterion_kwargs = {...}\n",
    "            evaluator = create_supervised_evaluator(\n",
    "                model,\n",
    "                metrics=metrics,\n",
    "                output_transform=lambda x, y, y_pred: {\n",
    "                    \"x\": x, \"y\": y, \"y_pred\": y_pred, \"criterion_kwargs\": criterion_kwargs}\n",
    "            )\n",
    "            res = evaluator.run(data)\n",
    "    \"\"\"\n",
    "\n",
    "    required_output_keys = (\"y_pred\", \"y\", \"criterion_kwargs\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        loss_fn: Callable,\n",
    "        output_transform: Callable = lambda x: x,\n",
    "        batch_size: Callable = len,\n",
    "        device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
    "    ):\n",
    "        super(Loss, self).__init__(output_transform, device=device)\n",
    "        self._loss_fn = loss_fn\n",
    "        self._batch_size = batch_size\n",
    "        self._device = device\n",
    "\n",
    "    @reinit__is_reduced\n",
    "    def reset(self) -> None:\n",
    "        self._sum = torch.tensor(0.0, device=self._device)\n",
    "        self._num_examples = 0\n",
    "\n",
    "    @reinit__is_reduced\n",
    "    def update(self, output: Sequence[Union[torch.Tensor, Dict]]) -> None:\n",
    "        print(f'loss device : {self._device}')\n",
    "        if len(output) == 2:\n",
    "            y_pred, y = cast(Tuple[torch.Tensor, torch.Tensor], output)\n",
    "            kwargs = {}  # type: Dict\n",
    "        else:\n",
    "            y_pred, y, kwargs = cast(Tuple[torch.Tensor, torch.Tensor, Dict], output)\n",
    "        \n",
    "        # label\n",
    "        y = torch.LongTensor([torch.argmax(y).item()]).to(self._device)\n",
    "\n",
    "        average_loss = self._loss_fn(y_pred, y, **kwargs).detach()\n",
    "\n",
    "        if len(average_loss.shape) != 0:\n",
    "            raise ValueError(\"loss_fn did not return the average loss.\")\n",
    "\n",
    "#         n = self._batch_size(y)\n",
    "        self._sum += average_loss.to(self._device)\n",
    "        self._num_examples += 1\n",
    "\n",
    "    @sync_all_reduce(\"_sum\", \"_num_examples\")\n",
    "    def compute(self) -> float:\n",
    "        if self._num_examples == 0:\n",
    "            return 0\n",
    "#             raise NotComputableError(\"Loss must have at least one example before it can be computed.\")\n",
    "        return self._sum.item() / self._num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "618d03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(evaluator, batch):\n",
    "    # ...\n",
    "    s = evaluator.state\n",
    "    print(\n",
    "        f\"{s.epoch}/{s.max_epochs} : {s.iteration} - {batch:.3f}\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b95edd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections.abc import Mapping\n",
    "from typing import Any, Callable, Dict, Optional, Sequence, Tuple, Union\n",
    "from ignite.handlers.checkpoint import ModelCheckpoint\n",
    "from ignite.utils import setup_logger\n",
    "from tqdm import tqdm\n",
    "from ignite.engine import Events, Engine\n",
    "from ignite.utils import convert_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96c5e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_batch(\n",
    "    batch: Sequence[torch.Tensor], device: Optional[Union[str, torch.device]] = None, non_blocking: bool = False\n",
    ") -> Tuple[Union[torch.Tensor, Sequence, Mapping, str, bytes], ...]:\n",
    "    \"\"\"Prepare batch for training: pass to a device with options.\n",
    "    \"\"\"\n",
    "    x, y = batch\n",
    "    return (\n",
    "        convert_tensor(x, device=device, non_blocking=non_blocking),\n",
    "        convert_tensor(y, device=device, non_blocking=non_blocking),\n",
    "    )\n",
    "\n",
    "def evaluation_step(\n",
    "    model: torch.nn.Module,\n",
    "    device: Optional[Union[str, torch.device]] = None,\n",
    "    non_blocking: bool = False,\n",
    "    prepare_batch: Callable = _prepare_batch,\n",
    "    output_transform: Callable = lambda x, y, y_pred: (y_pred, y),\n",
    ") -> Callable:\n",
    "    def evaluate_step(engine: Engine, batch: Sequence[torch.Tensor]) -> Union[Any, Tuple[torch.Tensor]]:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x, y = prepare_batch(batch, device=device, non_blocking=non_blocking)\n",
    "            \n",
    "            x_rep = model(x_raw=x)\n",
    "            y_pred = model(x_rep=x_rep)    \n",
    "            \n",
    "            return output_transform(x, y, y_pred)\n",
    "\n",
    "    return evaluate_step\n",
    "\n",
    "def create_evaluator(\n",
    "    model: torch.nn.Module,\n",
    "    metrics: Optional[Dict[str, Metric]] = None,\n",
    "    device: Optional[Union[str, torch.device]] = None,\n",
    "    non_blocking: bool = False,\n",
    "    prepare_batch: Callable = _prepare_batch,\n",
    "    output_transform: Callable = lambda x, y, y_pred: (y_pred, y),\n",
    "    amp_mode: Optional[str] = None,\n",
    ") -> Engine:\n",
    "    \n",
    "    '''\n",
    "    ref : https://github.com/pytorch/ignite/blob/master/ignite/engine/__init__.py > create_supervised_evaluator()\n",
    "    '''\n",
    "    metrics = metrics or {}\n",
    "    \n",
    "    eval_step = evaluation_step(model, device, non_blocking, prepare_batch, output_transform)\n",
    "    \n",
    "    evaluator = Engine(eval_step)\n",
    "    \n",
    "    for name, metric in metrics.items():\n",
    "        metric.attach(evaluator, name)\n",
    "        \n",
    "    return evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d214482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_trainer(model, optimizer, criterion, device, config=None, lr_scheduler=None):\n",
    "\n",
    "    # Define any training logic for iteration update\n",
    "    def train_step(engine, batch):\n",
    "        cs, ns, y = batch[0][0].to(device),batch[0][1].to(device), batch[1].to(device)\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        x_rep = model(x_raw=[cs, ns])\n",
    "        y_pred = model(x_rep=x_rep)\n",
    "        \n",
    "        # label\n",
    "        y = torch.LongTensor([torch.argmax(y).item()]).to(device)\n",
    "            \n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    # Define trainer engine\n",
    "    trainer = Engine(train_step)\n",
    "\n",
    "    return trainer\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def train(data, model, train_batch_size, val_batch_size, output_dir, model_filename, device, epochs, lr, betas=(0.9, 0.999), weight_decay: float = 0.01):\n",
    "    # epochs, batch_size, output_dir, lr, betas=(0.9, 0.999), weight_decay: float = 0.01, val_ratio=0.2, fp16=False, fp16_opt_level='O1'\n",
    "    \n",
    "    t_total, train_loader, val_loader = get_data_loaders(data, train_batch_size, val_batch_size)\n",
    "    \n",
    "    log_interval = int((t_total / train_batch_size) // 3)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "\n",
    "#     trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "    trainer = create_trainer(model, optimizer, criterion, device)\n",
    "    trainer.logger = setup_logger(\"trainer\")\n",
    "    evaluator = create_evaluator(model,\n",
    "                                 metrics={\n",
    "                                     'accuracy': RetrievalAccuracy(device=device),\n",
    "                                     'loss': Loss(criterion, device=device),\n",
    "                                },\n",
    "                                 device=device)\n",
    "    evaluator.logger = setup_logger(\"evaluator\")\n",
    "    \n",
    "    pbar = tqdm(initial=0, leave=False, total=t_total, desc=f\"ITERATION - loss: {0:.2f}\")\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    # execution after every log_interval\n",
    "    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
    "    def log_training_loss(engine):        \n",
    "        pbar.desc = f\"Epoch[{engine.state.epoch}] ITER {engine.state.iteration} - Loss: {engine.state.output:.2f}\"\n",
    "        pbar.update(log_interval)\n",
    " \n",
    "    # execution after every training epoch\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        # evaluate on training set\n",
    "        pbar.refresh()\n",
    "        evaluator.run(train_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics[\"accuracy\"]\n",
    "        avg_loss = metrics[\"loss\"]\n",
    "        tqdm.write(f\"Training Results - Epoch: {engine.state.epoch} Avg accuracy: {avg_accuracy:.2f} Avg loss: {avg_loss:.2f}\")\n",
    "        \n",
    "#         fp = \n",
    "#         torch.save(model.state_dict(), fp)\n",
    "\n",
    "\n",
    "    # execution after every epoch\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        # evaluate test(validation) set\n",
    "        evaluator.run(val_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics[\"accuracy\"]\n",
    "        avg_loss = metrics[\"loss\"]\n",
    "        tqdm.write(f\"Validation Results - Epoch: {engine.state.epoch} Avg accuracy: {avg_accuracy:.2f} Avg loss: {avg_loss:.2f}\")\n",
    "        pbar.n = pbar.last_print_n = 0\n",
    "        \n",
    "    @trainer.on(Events.EPOCH_COMPLETED | Events.COMPLETED)\n",
    "    def log_time(engine):\n",
    "        tqdm.write(f\"{trainer.last_event_name.name} took { trainer.state.times[trainer.last_event_name.name]} seconds\")\n",
    "    \n",
    "    ckpt = ModelCheckpoint(output_dir, model_filename, n_saved=3, create_dir=True)\n",
    "    trainer.add_event_handler(Events.EPOCH_COMPLETED(every=log_interval), ckpt, {'mymodel': model})\n",
    "    \n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "    pbar.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e71cd07e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ITERATION - loss: 0.00:   0%|                                                  | 0/256 [00:00<?, ?it/s]2021-09-04 16:14:54,946 trainer INFO: Engine run starting with max_epochs=100.\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   3%|█                                  | 8/256 [00:07<03:55,  1.05it/s]2021-09-04 16:15:02,679 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:02,679 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:02,680 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   3%|█                                  | 8/256 [00:07<03:55,  1.05it/s]2021-09-04 16:15:02,682 evaluator INFO: Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "y_pred 10, y 0\n",
      "_len : 1\n",
      "loss device : cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 16:15:03,133 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,134 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,136 trainer INFO: Epoch[1] Complete. Time taken: 00:00:08\n",
      "/home/super/.pyenv/versions/3.8.0/envs/waterffle/lib/python3.8/site-packages/ignite/engine/engine.py:793: UserWarning: Data iterator can not provide data anymore but required total number of iterations to run is not reached. Current iteration: 8 vs Total iterations to run : 800\n",
      "  warnings.warn(\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,137 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,138 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,138 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,139 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,140 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,140 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,209 trainer INFO: Epoch[2] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,210 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,211 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,211 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,212 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,213 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,213 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,215 trainer INFO: Epoch[3] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,216 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,217 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,217 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,218 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,219 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,219 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,222 trainer INFO: Epoch[4] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,222 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,223 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,223 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,224 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,225 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,225 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,227 trainer INFO: Epoch[5] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,228 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,229 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,229 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,230 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,231 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,231 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,234 trainer INFO: Epoch[6] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,234 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,235 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,235 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,236 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,237 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,237 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,239 trainer INFO: Epoch[7] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,240 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,241 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,241 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,242 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,243 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,243 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,245 trainer INFO: Epoch[8] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,246 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,247 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,247 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,248 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,249 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,249 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,251 trainer INFO: Epoch[9] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,251 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,252 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,252 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,254 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,254 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 16:15:03,254 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,257 trainer INFO: Epoch[10] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,258 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,258 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,258 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,260 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,261 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,261 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,263 trainer INFO: Epoch[11] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,263 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,264 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,264 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,266 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,266 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,267 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,269 trainer INFO: Epoch[12] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,270 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,270 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,271 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,272 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,272 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,273 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,275 trainer INFO: Epoch[13] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,275 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,276 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,276 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,277 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,278 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,278 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,281 trainer INFO: Epoch[14] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,282 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,282 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,283 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,284 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,285 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,285 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,287 trainer INFO: Epoch[15] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,288 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,288 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,288 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,290 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,290 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,290 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,293 trainer INFO: Epoch[16] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,294 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,294 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,295 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,296 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,296 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,297 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,299 trainer INFO: Epoch[17] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,299 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,300 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,300 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,301 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,302 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,302 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,305 trainer INFO: Epoch[18] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,305 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,306 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,306 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,307 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,308 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,308 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,310 trainer INFO: Epoch[19] Complete. Time taken: 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,311 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,312 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,312 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,313 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,314 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,314 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,317 trainer INFO: Epoch[20] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,317 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,318 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,318 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,319 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,320 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,320 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,323 trainer INFO: Epoch[21] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,323 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,324 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,324 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,325 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,326 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,326 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,329 trainer INFO: Epoch[22] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,330 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,330 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,330 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,332 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,332 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,332 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred 16, y 0\n",
      "_len : 2\n",
      "loss device : cuda:1\n",
      "Validation Results - Epoch: 1 Avg accuracy: 0.00 Avg loss: 6.43\n",
      "EPOCH_COMPLETED took 7.732387542724609 seconds\n",
      "Training Results - Epoch: 2 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 2 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 0.0005304813385009766 seconds\n",
      "Training Results - Epoch: 3 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 3 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 2.7418136596679688e-05 seconds\n",
      "Training Results - Epoch: 4 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 4 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 5 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 5 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 6 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 6 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 7 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 7 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 8 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 8 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8596649169921875e-05 seconds\n",
      "Training Results - Epoch: 9 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 9 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 10 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 10 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 11 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 11 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 12 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 12 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 2.002716064453125e-05 seconds\n",
      "Training Results - Epoch: 13 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 13 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 14 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 14 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 15 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 15 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 16 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 16 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 17 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 17 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 18 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 18 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8596649169921875e-05 seconds\n",
      "Training Results - Epoch: 19 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 19 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 20 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 20 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8596649169921875e-05 seconds\n",
      "Training Results - Epoch: 21 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 21 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 22 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 22 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 2.0265579223632812e-05 seconds\n",
      "Training Results - Epoch: 23 Avg accuracy: 0.00 Avg loss: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,335 trainer INFO: Epoch[23] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,335 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,336 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,336 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,337 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,338 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,338 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,341 trainer INFO: Epoch[24] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,342 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,342 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,342 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,344 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,344 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,345 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,347 trainer INFO: Epoch[25] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,347 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,348 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,348 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,349 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,350 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,350 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,353 trainer INFO: Epoch[26] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,354 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,354 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,354 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,355 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,356 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,356 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,359 trainer INFO: Epoch[27] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,359 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,360 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,360 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,361 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,362 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,362 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,365 trainer INFO: Epoch[28] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,365 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,366 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,366 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,367 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,368 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,368 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,370 trainer INFO: Epoch[29] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,371 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,371 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,372 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,373 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,373 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,374 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,376 trainer INFO: Epoch[30] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,377 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,377 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,378 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,379 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,379 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,380 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,382 trainer INFO: Epoch[31] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,382 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,383 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,383 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,385 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,385 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,385 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,388 trainer INFO: Epoch[32] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,389 evaluator INFO: Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 16:15:03,389 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,390 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,391 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,392 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,392 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,394 trainer INFO: Epoch[33] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,395 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,395 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,396 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,397 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,397 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,398 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,401 trainer INFO: Epoch[34] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,401 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,402 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,402 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,404 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,404 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,404 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,407 trainer INFO: Epoch[35] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,407 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,408 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,408 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,409 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,410 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,410 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,413 trainer INFO: Epoch[36] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,413 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,414 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,414 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,415 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,416 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,416 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,419 trainer INFO: Epoch[37] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,419 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,420 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,420 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,421 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,422 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,422 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,425 trainer INFO: Epoch[38] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,426 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,426 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,426 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,427 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,428 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,428 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,431 trainer INFO: Epoch[39] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,431 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,432 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,432 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,433 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,434 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,434 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,437 trainer INFO: Epoch[40] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,438 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,438 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,438 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,440 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,440 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,440 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,443 trainer INFO: Epoch[41] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,443 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,444 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,444 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,445 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,446 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 16:15:03,446 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,449 trainer INFO: Epoch[42] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,450 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,450 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,450 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,452 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,452 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,452 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,455 trainer INFO: Epoch[43] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,455 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,456 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,456 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,457 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,458 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,458 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,461 trainer INFO: Epoch[44] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,462 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,462 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,462 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,463 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,464 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,464 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,467 trainer INFO: Epoch[45] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,467 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,468 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,468 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,469 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,470 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,470 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,473 trainer INFO: Epoch[46] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,474 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,474 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,474 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,475 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,476 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,476 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,479 trainer INFO: Epoch[47] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,479 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,480 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,480 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,481 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,482 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,482 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,485 trainer INFO: Epoch[48] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,486 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,486 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,486 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,487 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,488 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,488 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,491 trainer INFO: Epoch[49] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,491 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,492 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,492 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,493 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,494 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,494 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,497 trainer INFO: Epoch[50] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,498 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,498 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,498 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,500 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,500 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,500 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,503 trainer INFO: Epoch[51] Complete. Time taken: 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,503 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,504 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,504 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,505 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,506 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,506 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,509 trainer INFO: Epoch[52] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,510 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,510 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,510 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,511 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,512 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,512 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,514 trainer INFO: Epoch[53] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,515 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,516 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,516 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,517 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,518 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,518 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,521 trainer INFO: Epoch[54] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,521 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,522 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,522 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,523 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,524 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,524 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,527 trainer INFO: Epoch[55] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,527 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,528 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,528 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,529 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,530 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,530 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,533 trainer INFO: Epoch[56] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,533 evaluator INFO: Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 23 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 24 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 24 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8358230590820312e-05 seconds\n",
      "Training Results - Epoch: 25 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 25 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 26 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 26 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8596649169921875e-05 seconds\n",
      "Training Results - Epoch: 27 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 27 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8596649169921875e-05 seconds\n",
      "Training Results - Epoch: 28 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 28 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8596649169921875e-05 seconds\n",
      "Training Results - Epoch: 29 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 29 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 30 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 30 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 31 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 31 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 32 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 32 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 33 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 33 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 34 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 34 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 35 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 35 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 36 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 36 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 37 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 37 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 38 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 38 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 39 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 39 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 40 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 40 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9788742065429688e-05 seconds\n",
      "Training Results - Epoch: 41 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 41 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 42 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 42 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 43 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 43 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 44 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 44 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 45 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 45 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 46 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 46 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 47 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 47 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 48 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 48 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 49 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 49 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 50 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 50 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 51 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 51 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 52 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 52 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 53 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 53 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 54 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 54 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 55 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 55 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 56 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 56 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 16:15:03,534 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,534 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,536 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,536 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,536 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,539 trainer INFO: Epoch[57] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,539 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,540 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,540 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,541 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,542 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,542 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,545 trainer INFO: Epoch[58] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,546 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,546 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,546 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,548 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,548 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,549 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,551 trainer INFO: Epoch[59] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,551 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,552 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,552 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,554 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,554 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,554 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,557 trainer INFO: Epoch[60] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,558 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,558 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,559 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,560 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,560 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,561 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,563 trainer INFO: Epoch[61] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,563 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,564 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,564 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,566 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,566 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,566 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,569 trainer INFO: Epoch[62] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,570 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,570 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,571 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,572 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,572 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,573 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,575 trainer INFO: Epoch[63] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,575 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,576 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,576 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,578 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,578 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,579 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,581 trainer INFO: Epoch[64] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,582 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,582 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,583 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,584 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,584 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,585 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,587 trainer INFO: Epoch[65] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,588 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,588 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,589 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,590 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,590 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 16:15:03,591 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,594 trainer INFO: Epoch[66] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,594 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,595 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,595 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,596 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,597 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,597 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,599 trainer INFO: Epoch[67] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,600 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,600 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,601 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,602 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,603 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,603 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,606 trainer INFO: Epoch[68] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,606 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,607 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,607 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,608 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,609 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,609 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,611 trainer INFO: Epoch[69] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,612 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,613 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,613 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,614 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,615 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,615 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,618 trainer INFO: Epoch[70] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,618 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,619 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,619 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,620 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,621 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,621 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,623 trainer INFO: Epoch[71] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,624 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,625 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,625 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,626 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,627 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,627 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,630 trainer INFO: Epoch[72] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,630 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,631 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,631 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,632 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,633 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,633 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,635 trainer INFO: Epoch[73] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,636 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,637 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,637 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,638 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,639 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,639 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,642 trainer INFO: Epoch[74] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,642 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,643 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,643 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,644 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,645 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,645 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,647 trainer INFO: Epoch[75] Complete. Time taken: 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,648 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,649 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,649 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,650 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,651 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,651 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,654 trainer INFO: Epoch[76] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,654 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,655 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,655 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,656 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,657 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,657 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,660 trainer INFO: Epoch[77] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,660 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,661 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,661 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,662 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,663 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,663 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,666 trainer INFO: Epoch[78] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,666 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,667 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,667 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,668 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,669 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,669 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,672 trainer INFO: Epoch[79] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,672 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,673 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,673 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,674 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,675 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,675 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,678 trainer INFO: Epoch[80] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,678 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,679 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,679 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,680 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,681 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,681 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,684 trainer INFO: Epoch[81] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,684 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,685 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,685 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,686 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,687 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,687 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,690 trainer INFO: Epoch[82] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,690 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,691 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,691 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,692 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,693 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,693 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,696 trainer INFO: Epoch[83] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,696 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,697 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,697 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,698 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,699 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,699 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,702 trainer INFO: Epoch[84] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,703 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,703 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,703 evaluator INFO: Engine run complete. Time taken: 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,705 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,705 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,705 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,708 trainer INFO: Epoch[85] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,708 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,709 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,709 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,710 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,711 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,711 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,714 trainer INFO: Epoch[86] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,715 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,715 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,715 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,717 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,717 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,717 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,720 trainer INFO: Epoch[87] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,720 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,721 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,721 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,726 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,727 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,727 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,730 trainer INFO: Epoch[88] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,730 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,731 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,731 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,732 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,733 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,733 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,735 trainer INFO: Epoch[89] Complete. Time taken: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 57 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 57 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 58 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 58 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 59 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 59 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 60 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 60 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 61 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 61 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 62 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 62 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 63 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 63 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 64 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 64 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9788742065429688e-05 seconds\n",
      "Training Results - Epoch: 65 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 65 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 66 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 66 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 67 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 67 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 68 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 68 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 2.002716064453125e-05 seconds\n",
      "Training Results - Epoch: 69 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 69 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 70 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 70 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 2.002716064453125e-05 seconds\n",
      "Training Results - Epoch: 71 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 71 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 72 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 72 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 73 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 73 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 74 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 74 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 75 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 75 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 76 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 76 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 77 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 77 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 78 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 78 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9788742065429688e-05 seconds\n",
      "Training Results - Epoch: 79 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 79 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 80 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 80 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 81 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 81 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 82 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 82 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 83 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 83 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 84 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 84 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 85 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 85 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 86 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 86 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 87 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 87 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 88 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 88 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 89 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 89 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,736 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,737 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,737 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,738 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,739 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,739 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,742 trainer INFO: Epoch[90] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,742 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,743 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,743 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,744 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,745 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,745 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,748 trainer INFO: Epoch[91] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,748 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,749 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,749 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,750 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,751 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,751 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,754 trainer INFO: Epoch[92] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,755 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,755 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,755 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,757 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,757 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,757 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,760 trainer INFO: Epoch[93] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,760 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,761 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,761 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,762 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,763 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,763 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,766 trainer INFO: Epoch[94] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,767 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,767 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,768 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,769 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,770 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,770 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,772 trainer INFO: Epoch[95] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,773 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,773 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,774 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,775 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,776 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,776 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,779 trainer INFO: Epoch[96] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,779 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,780 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,780 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,781 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,782 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,782 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,785 trainer INFO: Epoch[97] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,785 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,786 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,786 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,787 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,788 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,788 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,791 trainer INFO: Epoch[98] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,792 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,792 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,792 evaluator INFO: Engine run complete. Time taken: 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,794 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,794 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,795 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,797 trainer INFO: Epoch[99] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,797 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,798 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,799 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,800 evaluator INFO: Engine run starting with max_epochs=1.\n",
      "2021-09-04 16:15:03,800 evaluator INFO: Epoch[1] Complete. Time taken: 00:00:00\n",
      "2021-09-04 16:15:03,801 evaluator INFO: Engine run complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,804 trainer INFO: Epoch[100] Complete. Time taken: 00:00:00\n",
      "Epoch[1] ITER 8 - Loss: 12.46:   0%|                                   | 0/256 [00:08<04:03,  1.05it/s]2021-09-04 16:15:03,805 trainer INFO: Engine run complete. Time taken: 00:00:09\n",
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 90 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 90 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 91 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 91 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.8835067749023438e-05 seconds\n",
      "Training Results - Epoch: 92 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 92 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9311904907226562e-05 seconds\n",
      "Training Results - Epoch: 93 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 93 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 94 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 94 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 95 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 95 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 96 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 96 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "Training Results - Epoch: 97 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 97 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 98 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 98 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 99 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 99 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9073486328125e-05 seconds\n",
      "Training Results - Epoch: 100 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "Validation Results - Epoch: 100 Avg accuracy: 0.00 Avg loss: 0.00\n",
      "EPOCH_COMPLETED took 1.9550323486328125e-05 seconds\n",
      "COMPLETED took 8.857898950576782 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100 # epoch\n",
    "batch_size=32 # batch size for training\n",
    "lr=1e-5 # learning rate\n",
    "device='cuda:1'\n",
    "train([cs, ns, labels], \n",
    "      model, \n",
    "      train_batch_size=batch_size, \n",
    "      val_batch_size=batch_size, \n",
    "      output_dir='.', \n",
    "      model_filename='ignite-poly-64-0904', \n",
    "      device=device, \n",
    "      epochs=epochs, \n",
    "      lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = [cs.to(device_num), ns.to(device_num), labels.to(device_num)]\n",
    "# batch_size, C, H, W = 32, 1, 28, 28\n",
    "# tdata = [torch.randn(batch_size, C, H, W).to(1),torch.randn(batch_size, C, H, W).to(1), torch.randn(batch_size).to(1)]\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100 # epoch\n",
    "batch_size=32 # batch size for training\n",
    "lr=1e-5 # learning rate\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#             optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "\n",
    "train(model=model.to(device_num), \n",
    "      raw_data=tdata, \n",
    "      epochs=epochs, \n",
    "      batch_size=batch_size, \n",
    "      output_dir='.', \n",
    "      lr=lr,\n",
    "      val_ratio=0.2, \n",
    "      fp16=False, \n",
    "      fp16_opt_level='O1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4c05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b2cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd1fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(dataloader, criterion):\n",
    "    # layer 중 dropout layer와 같이 학습 시에는 사용하는데 inference할 때는 사용하지 않는 경우를 구분해주기 위함\n",
    "    model.eval()\n",
    "    \n",
    "    n_steps = 0\n",
    "    eval_loss = 0    \n",
    "    acc = 0\n",
    "\n",
    "    # autograd engine을 끔(gradient 계산하지 않음) --> 메모리 사용량을 줄이고 연산 속도를 높이기 위함\n",
    "    with torch.no_grad():\n",
    "        # input은 이미 1차 임베딩은 되어 있는 것을 가져왔다고 가정한다.\n",
    "        for idx, (batch_cs, batch_ns, batch_label) in enumerate(dataloader):\n",
    "            n_steps+=1\n",
    "            # mfcc embedding encoder\n",
    "            cs_rep, ns_rep, label = model(x_raw=[batch_cs, batch_ns, batch_label])\n",
    "\n",
    "            batch_label = torch.LongTensor([torch.argmax(label).item()]).to(device_num)\n",
    "            scores = model(x_rep=[cs_rep, ns_rep])\n",
    "            \n",
    "#             print(f'eval score : {scores}')\n",
    "                \n",
    "            loss = criterion(scores, batch_label)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "#             print(f'predict : {torch.argmax(scores, axis=1)}')\n",
    "#             print(f'label.  : {batch_label}')\n",
    "            if torch.argmax(scores, axis=1) == batch_label:\n",
    "                acc += 1\n",
    "\n",
    "    results = {\n",
    "        'eval_accuracy': acc / n_steps,\n",
    "        'eval_loss': eval_loss / n_steps\n",
    "    }\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec23acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11faa91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def train(model, raw_data, epochs, batch_size, output_dir, lr, betas=(0.9, 0.999), weight_decay: float = 0.01, val_ratio=0.2, fp16=False, fp16_opt_level='O1'):\n",
    "#     no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    \n",
    "#     optimizer_grouped_parameters = [\n",
    "#         {\n",
    "#             \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#             \"weight_decay\": weight_decay,\n",
    "#         },\n",
    "#         {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "#     ]\n",
    "    \n",
    "\n",
    "    \n",
    "    # fp16=True면 amp를 통한 mixed preicision training을 한다는 의미\n",
    "    # 사용 조건 : Volta 이상의 nvidia 그래픽 카드(v100, rtx2080ti, 등)\n",
    "    if fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=fp16_opt_level)\n",
    "    \n",
    "    def train_batch(data, bsz, shuffle=True):\n",
    "        cs_rep, ns_rep, labels = data\n",
    "        length = cs_rep.size()[0]\n",
    "        \n",
    "        for i in range(0, length, bsz):\n",
    "            cs_batch = cs_rep[i:i+bsz]\n",
    "            ns_batch = ns_rep[i:i+bsz]\n",
    "            label_batch = labels[i:i+bsz]\n",
    "            \n",
    "            if shuffle:\n",
    "                indexes = torch.randperm(bsz)              \n",
    "                yield [cs_batch[indexes], ns_batch[indexes], label_batch[indexes]]\n",
    "            else:\n",
    "                yield [cs_batch, ns_batch, label_batch]    \n",
    "    state_save_path = os.path.join(output_dir, '{}_{}_{}_pytorch_model.bin'.format('polyencoder', '64', '0815'))\n",
    "        \n",
    "    best_eval_loss = float('inf')\n",
    "    best_test_loss = float('inf')\n",
    "    \n",
    "    cs, ns, labels = raw_data\n",
    "        \n",
    "    init_time = time.time()\n",
    "    # 재사용 가능한 임베딩들은 미리 뽑기\n",
    "    trainset = None\n",
    "    valset = None\n",
    "\n",
    "    if val_ratio > 0:\n",
    "        train_len = int((1-val_ratio)*len(labels))\n",
    "        trainset = [cs[:train_len], ns[:train_len], labels[:train_len]]\n",
    "        valset = [cs[train_len:], ns[train_len:], labels[train_len:]]\n",
    "    else:\n",
    "        trainset = raw_data\n",
    "\n",
    "    eval_freq = (len(trainset[2]) / batch_size) // 3\n",
    "    \n",
    "    t_total = len(trainset[0])\n",
    "    \n",
    "#     optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=1e-8)\n",
    "#     scheduler = get_linear_schedule_with_warmup(\n",
    "#         optimizer, num_warmup_steps=100, num_training_steps=t_total\n",
    "#     )\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "\n",
    "    # Set the learning rate of each parameter group using a cosine annealing schedule,\n",
    "    # https://pytorch.org/docs/1.8.0/optim.html?highlight=cosineannealingwarmrestarts#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    \n",
    "    # stepRL\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=eval_freq, gamma=0.95)\n",
    "\n",
    "        \n",
    "    batch_labels = []\n",
    "    scores = []\n",
    "    global_step = 0\n",
    "    #TODO : 나중에 tqdm으로 바꾸기\n",
    "    for epoch in range(1, epochs+1):\n",
    "        start_time = time.time()\n",
    "        train_batches = train_batch(trainset, batch_size)\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        accuracy = 0.0\n",
    "        local_step = 0\n",
    "        for idx, (batch_cs, batch_ns, batch_label) in enumerate(train_batches):\n",
    "            model.train()\n",
    "            \n",
    "            # mfcc embedding encoder\n",
    "            cs_rep, ns_rep, label = model(x_raw=[batch_cs, batch_ns, batch_label])\n",
    "            \n",
    "            # label\n",
    "            batch_label = torch.LongTensor([torch.argmax(batch_label).item()]).to(device_num)\n",
    "            \n",
    "            # dot product\n",
    "            scores = model(x_rep=[cs_rep, ns_rep])\n",
    "#             print(f'scores : {scores}')\n",
    "\n",
    "            # cross entropy\n",
    "            loss = criterion(scores, batch_label)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            predict = torch.argmax(scores, axis=1)\n",
    "#             print('predict : ',predict.item())\n",
    "#             print(f'label : {batch_label.item()}\\n')\n",
    "#             if predict == torch.argmax(batch_label).item():\n",
    "            if predict == batch_label:\n",
    "                accuracy += 1\n",
    "#                 print(f'-- correct : {accuracy}\\n')\n",
    "            \n",
    "            if torch.isnan(loss):\n",
    "                print(f'scores : {scores}')\n",
    "                exit()\n",
    "            \n",
    "            if fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "#             scheduler.step()\n",
    "\n",
    "            # clear gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "#             model.zero_grad()\n",
    "            \n",
    "#             if global_step and global_step % eval_freq == 0:\n",
    "#                 if valset is not None:\n",
    "#                     val_batches = train_batch(valset, batch_size, shuffle=False)\n",
    "\n",
    "#                 eval_results = eval_model(val_batches, criterion)\n",
    "#                 scheduler.step(eval_results['eval_loss'])\n",
    "\n",
    "#                 print(f'Global Step {global_step} Eval loss : {eval_results[\"eval_loss\"]}, Eval accuracy : {eval_results[\"eval_accuracy\"]}')\n",
    "#                 if eval_results[\"eval_loss\"] < best_eval_loss:\n",
    "#                     best_eval_loss = eval_results['eval_loss']\n",
    "#                     # save model.state_dict()\n",
    "#                     torch.save(model.state_dict(), state_save_path)\n",
    "#                     print(f'[Saving at] {state_save_path}')\n",
    "\n",
    "            \n",
    "            global_step += 1\n",
    "            local_step += 1\n",
    "\n",
    "            #print(f'batch {idx} | Loss {loss.item()}')\n",
    "        \n",
    "        total_loss = total_loss / local_step\n",
    "        train_accuracy = accuracy / local_step\n",
    "        print(f'\\n[Epoch {epoch}] | train_cost {total_loss} | train_accuracy {train_accuracy} | time {time.time()-start_time}')\n",
    "        \n",
    "        if valset is not None:\n",
    "            val_batches = train_batch(valset, batch_size, shuffle=False)\n",
    "        eval_results = eval_model(val_batches, criterion)\n",
    "        print(f'Eval loss : {eval_results[\"eval_loss\"]}, Eval accuracy : {eval_results[\"eval_accuracy\"]}')\n",
    "        if eval_results[\"eval_loss\"] < best_eval_loss:\n",
    "            best_eval_loss = eval_results['eval_loss']\n",
    "            # save model.state_dict()\n",
    "            torch.save(model.state_dict(), state_save_path)\n",
    "#             print(f'[Saving at] {state_save_path}')\n",
    "        print('---------------------------------\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed9f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1] | train_cost 2.9114290095865725 | train_accuracy 0.1625 | time 74.13653993606567\n",
      "Eval loss : 6.218299305438995, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 2] | train_cost 2.331125350110233 | train_accuracy 0.2 | time 74.33295392990112\n",
      "Eval loss : 6.199160850048065, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 3] | train_cost 2.400858477782458 | train_accuracy 0.2625 | time 74.48530435562134\n",
      "Eval loss : 6.528730642795563, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 4] | train_cost 2.261480643879622 | train_accuracy 0.2625 | time 74.50722742080688\n",
      "Eval loss : 6.581989181041718, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 5] | train_cost 2.355602344824001 | train_accuracy 0.275 | time 74.5271053314209\n",
      "Eval loss : 6.960526299476624, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 6] | train_cost 2.4346638480201364 | train_accuracy 0.175 | time 74.52601099014282\n",
      "Eval loss : 6.6351118087768555, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 7] | train_cost 2.391763858590275 | train_accuracy 0.2375 | time 74.53262829780579\n",
      "Eval loss : 6.877604305744171, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 8] | train_cost 2.1604465214535593 | train_accuracy 0.25 | time 74.53560972213745\n",
      "Eval loss : 6.550958824157715, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 9] | train_cost 2.3228407077491284 | train_accuracy 0.2625 | time 74.52826523780823\n",
      "Eval loss : 6.935123217105866, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 10] | train_cost 2.4035882003605367 | train_accuracy 0.1625 | time 74.52900958061218\n",
      "Eval loss : 7.27074921131134, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 11] | train_cost 2.0693064448889347 | train_accuracy 0.325 | time 74.53088903427124\n",
      "Eval loss : 7.684620046615601, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 12] | train_cost 2.165913598355837 | train_accuracy 0.225 | time 74.5401382446289\n",
      "Eval loss : 7.545060575008392, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 13] | train_cost 2.052245264220983 | train_accuracy 0.3 | time 74.53142309188843\n",
      "Eval loss : 7.13888680934906, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 14] | train_cost 1.953722728881985 | train_accuracy 0.325 | time 74.53524541854858\n",
      "Eval loss : 7.70440137386322, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 15] | train_cost 2.0574665057007224 | train_accuracy 0.325 | time 74.53529953956604\n",
      "Eval loss : 7.546217727661133, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 16] | train_cost 1.787168186204508 | train_accuracy 0.3375 | time 74.53705549240112\n",
      "Eval loss : 8.299888503551482, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 17] | train_cost 1.7410835280184984 | train_accuracy 0.3375 | time 74.54080414772034\n",
      "Eval loss : 8.40029592514038, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 18] | train_cost 1.781722459947923 | train_accuracy 0.4 | time 74.54082107543945\n",
      "Eval loss : 8.570691800117492, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 19] | train_cost 1.8066425064927898 | train_accuracy 0.35 | time 74.52371120452881\n",
      "Eval loss : 8.779009103775024, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 20] | train_cost 1.5861184075765777 | train_accuracy 0.4625 | time 74.53771448135376\n",
      "Eval loss : 8.909149789810181, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 21] | train_cost 1.6247244358259194 | train_accuracy 0.4125 | time 74.53528809547424\n",
      "Eval loss : 9.623294568061828, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 22] | train_cost 1.3521558844688115 | train_accuracy 0.475 | time 74.5332498550415\n",
      "Eval loss : 10.275758504867554, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 23] | train_cost 1.6519393280482462 | train_accuracy 0.4625 | time 74.53442478179932\n",
      "Eval loss : 10.014787244796754, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 24] | train_cost 1.2579689578022226 | train_accuracy 0.6375 | time 74.5415666103363\n",
      "Eval loss : 10.972245717048645, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 25] | train_cost 1.1325215602131038 | train_accuracy 0.6125 | time 74.53480672836304\n",
      "Eval loss : 12.799834370613098, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 26] | train_cost 0.8218928040458422 | train_accuracy 0.7 | time 74.53980612754822\n",
      "Eval loss : 13.872412419319152, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 27] | train_cost 0.6181365768799949 | train_accuracy 0.7875 | time 74.53018236160278\n",
      "Eval loss : 14.113038408756257, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 28] | train_cost 0.45942042020686813 | train_accuracy 0.8125 | time 74.53540921211243\n",
      "Eval loss : 15.635555565357208, Eval accuracy : 0.05\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 29] | train_cost 0.416020314848015 | train_accuracy 0.875 | time 74.53684878349304\n",
      "Eval loss : 17.750123822689055, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 30] | train_cost 0.5037281240152425 | train_accuracy 0.875 | time 74.53704500198364\n",
      "Eval loss : 18.377840328216553, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 31] | train_cost 0.6871987506565453 | train_accuracy 0.8375 | time 74.53615999221802\n",
      "Eval loss : 20.580799555778505, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 32] | train_cost 0.5155575672424475 | train_accuracy 0.8125 | time 74.53380227088928\n",
      "Eval loss : 19.163234615325926, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 33] | train_cost 0.4402472201743982 | train_accuracy 0.875 | time 74.53479480743408\n",
      "Eval loss : 18.98086085319519, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 34] | train_cost 0.26880129643661227 | train_accuracy 0.95 | time 74.52902245521545\n",
      "Eval loss : 20.975797653198242, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 35] | train_cost 0.05366491751255884 | train_accuracy 0.9875 | time 74.53735899925232\n",
      "Eval loss : 21.83808422088623, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 36] | train_cost 0.020458074550129535 | train_accuracy 1.0 | time 74.53831005096436\n",
      "Eval loss : 21.818930220603942, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 37] | train_cost 0.06833715409469994 | train_accuracy 0.975 | time 74.53773784637451\n",
      "Eval loss : 20.282481384277343, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 38] | train_cost 0.11327738523162285 | train_accuracy 0.9625 | time 74.54144263267517\n",
      "Eval loss : 21.28538248538971, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 39] | train_cost 0.14757679154804038 | train_accuracy 0.95 | time 74.53723740577698\n",
      "Eval loss : 19.943018507957458, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 40] | train_cost 0.03388884255991078 | train_accuracy 0.9875 | time 74.53251099586487\n",
      "Eval loss : 20.09693579673767, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 41] | train_cost 0.17579747463535184 | train_accuracy 0.9375 | time 74.53392839431763\n",
      "Eval loss : 18.20582320690155, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 42] | train_cost 0.05730254969601782 | train_accuracy 0.9625 | time 74.52752017974854\n",
      "Eval loss : 19.361207437515258, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 43] | train_cost 0.011612736423832804 | train_accuracy 1.0 | time 74.52916955947876\n",
      "Eval loss : 20.78713767528534, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 44] | train_cost 0.0044019957620832885 | train_accuracy 1.0 | time 74.53812575340271\n",
      "Eval loss : 21.12484574317932, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 45] | train_cost 0.00791885112485886 | train_accuracy 1.0 | time 74.53585314750671\n",
      "Eval loss : 21.92399799823761, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "[Epoch 46] | train_cost 0.0010917904887963736 | train_accuracy 1.0 | time 74.53459596633911\n",
      "Eval loss : 21.765058279037476, Eval accuracy : 0.0\n",
      "---------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RuntimeError: Expected 4-dimensional input for 4-dimensional weight [256, 1, 3, 3], but got 3-dimensional input of size [320, 40, 2800] instead\n",
    "# tdata = [now_mfcc_list.to(1), next_mfcc_list.to(1), label_list.to(1)]\n",
    "tdata = [cs.to(device_num), ns.to(device_num), labels.to(device_num)]\n",
    "# batch_size, C, H, W = 32, 1, 28, 28\n",
    "# tdata = [torch.randn(batch_size, C, H, W).to(1),torch.randn(batch_size, C, H, W).to(1), torch.randn(batch_size).to(1)]\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100 # epoch\n",
    "batch_size=32 # batch size for training\n",
    "lr=1e-5 # learning rate\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#             optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "\n",
    "train(model=model.to(device_num), \n",
    "      raw_data=tdata, \n",
    "      epochs=epochs, \n",
    "      batch_size=batch_size, \n",
    "      output_dir='.', \n",
    "      lr=lr,\n",
    "      val_ratio=0.2, \n",
    "      fp16=False, \n",
    "      fp16_opt_level='O1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967a8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c27768ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original : torch.Size([32, 32])\n",
      "tensor([[ 2.4609,  2.9383, -0.0992,  ...,  1.5904, -0.4699, -0.3806],\n",
      "        [ 1.4856, -1.7485, -0.7887,  ...,  0.5148, -1.7101,  1.5381],\n",
      "        [-1.4856,  0.5917, -0.4003,  ..., -0.6114, -0.2885,  1.0095],\n",
      "        ...,\n",
      "        [ 0.1101,  0.3752, -1.4103,  ..., -0.7080, -2.1661,  1.6945],\n",
      "        [ 0.6835,  0.1333, -1.1536,  ...,  0.2719,  0.2294, -0.0227],\n",
      "        [-1.2907,  1.2089, -0.3617,  ...,  0.3123, -1.5061, -0.4800]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#             2. max 값으로 대표값 정해서 cross entropy 32,32 -> 32, 1 -> 1, 32\n",
    "#             3. mean 값으로 대표값 정해서 cross entropy 32, 32 -> 32,1 -> 1, 32\n",
    "\n",
    "x = torch.randn((32,32))\n",
    "print(f'original : {x.size()}\\n{x}')\n",
    "# x = torch.max(x, dim=-1)\n",
    "# x = x.values.view(1, -1)\n",
    "# x.size()\n",
    "\n",
    "x = torch.mean(x, dim=-1)\n",
    "x = x.view(1, -1)\n",
    "x.size()\n",
    "\n",
    "# x = F.softmax(x)\n",
    "# print(x.size())\n",
    "# y = torch.LongTensor([1])\n",
    "# y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af893fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "print(cross_entropy_loss(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb308e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[2, 0.805, 0.6393]])\n",
    "x = F.softmax(x)\n",
    "print(x.size())\n",
    "y = torch.LongTensor([0])\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5cdaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "print(cross_entropy_loss(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = torch.LongTensor([1])\n",
    "print(cross_entropy_loss(x, y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a63290",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27594/800029942.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "y2 = torch.LongTensor([2])\n",
    "print(cross_entropy_loss(x, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4)\n",
    "print(a)\n",
    "a = torch.LongTensor([torch.argmax(a).item()])\n",
    "print(a)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.LongTensor([1])\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([[2.0959e-02, 2.0501e-04, 1.5565e-02, 5.2595e-02, 1.3077e-05, 1.2790e-03,\n",
    "         3.7969e-01, 3.6344e-05, 1.1723e-01, 5.2833e-02, 2.7906e-05, 2.4717e-04,\n",
    "         4.2139e-05, 3.3961e-04, 1.4989e-05, 1.3840e-03, 1.6910e-02, 1.2072e-03,\n",
    "         2.4667e-02, 2.1032e-03, 2.3573e-01, 3.0013e-02, 6.1480e-04, 1.3032e-02,\n",
    "         7.4176e-03, 1.4105e-02, 5.0791e-04, 9.9195e-04, 2.5835e-05, 7.1133e-03,\n",
    "         6.1536e-04, 2.4788e-03]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca627b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27594/1691618489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b97542",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.LongTensor([6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c98c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d7d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x.size()[1]):\n",
    "    y = torch.LongTensor([i])\n",
    "    cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "    print(cross_entropy_loss(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae21cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
